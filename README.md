- ğŸ‘‹ Hi, Iâ€™m @Supercalafragalisticexpialadoscious
- ğŸ‘€ Iâ€™m interested in ...
- ğŸŒ± Iâ€™m currently learning ...
- ğŸ’ï¸ Iâ€™m looking to collaborate on ...
- ğŸ“« How to reach me ...

<!---
Supercalafragalisticexpialadoscious/Supercalafragalisticexpialadoscious is a âœ¨ special âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.
You can click the Preview link to take a look at your changes.
--->
This is a ridiculous name but appears to be the only option left in the cyber universe!

- ğŸ‘€ Iâ€™m interested in ...
Well, not an easy question to answer in one part but here goes:

"Removing software development from the red line in project planning".... (Sorry Prof. Brooks)

Now with that behind us, the obvious question is how can we do this. Answer is obvious:
- get rid of duplication in all its forms(not to be confused with replication).  

Next question is how?
Once again, very simply - reduce everything (and I mean everything) to its foundational atomic components and then use an index to deliver a structure. Then index the structures to deliver compound structures. Repeat.

Next question - what is everything? 

By now you will hopefully understand software consists of algorithms and stuff (found inside code) and data -  data is fed to the algorithms and value added - what's expressed is data but with the changes as prescribed by the algorithm. Repeat to deliver final requirement.
Now if everything is algorithms and data (later referred to as logic and rule) then is this all? 

Nope. 

algorithms and data combine to form structure. 

As in the proverbial 'outside the box' analogy, we generally fail to look beyond the paper and the dot. Logic and rule are visible, the structure is not that obvious but in electronic terms ubiquitous. 

To summarise, logic and rule (analogous cyber equivalent to energy and matter) interact to deliver a unique structure - a data persisted in some fashion awaiting the next cycle of change - atomic structures associate to form compound structures. Repeat
Now to answer the original question (...ğŸ‘€ I'm interested in) here is a more serious answer 

- identifying mechanisms which reduce the index of reuse of logic by 100%. 
- 
ğŸŒ± Iâ€™m currently learning ...

Using metaobjects realised from basic atomic components, it can be demonstrated that an infinite number of structural phenotypes (Whew) can be realised using a FINITE number of logic components. In very simple terms, create a base layer of components each with a unique pointer identification and then a universe of relational pointers manipulating these and other other pointers.

In essence, the focus is to do to logic (transitional aspect) what normalisation has done to rule (persistent aspect). Difficult to understand perhaps, defintaly difficult to expplain - a binary database  will be published soon to make this concept more concrete.

ğŸ’ï¸ Iâ€™m looking to collaborate on ...

Well, here it becomes vague. The concept has been tested in a PhD, the executable provides output as would be expected, explaining the 'engine' is really hard!  The problem is the work has been done in isolation. I have a limited understanding of mainstream terminology, and invented terms are not grasped by the recipients.  An informal soundboard with an academic / industry specialist to classify the work would really be appreciated. Who knows, it may be of value. 

What can be said is current understanding of market products indicates that they largely make use of existing structures, templates and generators. This approach was initially tried and subsequently discarded in the 90's - granularity was too rough.  Final approach as mentioned above has an absolute granularity in terms of the reuse of logic and can cater for subtypes, recusion and iterative requirements. Enough!

- ğŸ“« How to reach me ...
- robertwilliamlemke@yahoo.com

